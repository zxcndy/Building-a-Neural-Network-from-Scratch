{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(sys.argv)\n",
    "\n",
    "train_input = files[1]\n",
    "test_input = files[2]\n",
    "train_out = files[3]\n",
    "test_out = files[4]\n",
    "metrics_out = files[5]\n",
    "\n",
    "num_epoch = int(files[6]) #number of epochs\n",
    "hidden_units = int(files[7]) #number of hidden units\n",
    "init_flag = int(files[8]) #choose between 1 random or 2 zero\n",
    "learning_rate = float(files[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation of the first layer\n",
    "def sigmoid(a):\n",
    "    return 1/(1+np.exp(-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNforward(train,train_y,alpha,beta):\n",
    "    a = np.dot(alpha,train.T)\n",
    "    z = sigmoid(a)\n",
    "    z= np.insert(z,0,1)\n",
    "    \n",
    "    b = np.dot(beta,z)\n",
    "    exp_scores = np.exp(b.T)\n",
    "    probs = exp_scores / np.sum(exp_scores) #softmax\n",
    "    y_hat = np.argmax(probs)\n",
    "    return probs,y_hat,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNBackward(train,train_y,alpha,beta,probs,z):\n",
    "    dLdB = np.copy(probs)\n",
    "    dLdB[train_y] = dLdB[train_y] -1\n",
    "\n",
    "    dLdB = np.reshape(dLdB, (-1, len(dLdB)))\n",
    "    z = np.reshape(z, (-1, len(z)))\n",
    "    dLdBeta = np.dot(dLdB.T, z)\n",
    "    \n",
    "    beta_star = np.copy(beta[:,1:])\n",
    "    #print(beta_star)\n",
    "    dLdZ = np.dot(dLdB,beta_star)\n",
    "    z_star = np.copy(z[0][1:])\n",
    "    \n",
    "    #print(z.shape,dLdZ.shape)\n",
    "    dLdA = dLdZ*z_star*(1-z_star)\n",
    "    #print(dLdA.shape)\n",
    "    train = np.reshape(train, (-1, len(train)))\n",
    "    dLdAlpha = np.dot(dLdA.T,train)\n",
    "    return dLdAlpha, dLdBeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_loss(probs,y):\n",
    "    l = probs[y] #find the probability\n",
    "    s = -np.log(l)   \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hidden_units = 4 #number of hidden units\n",
    "init_flag = 2 #choose between 1 random or 2 zero\n",
    "num_epoch = 2 #number of epochs\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_input = \"./handout/smallTrain.csv\"\n",
    "test_input = \"./handout/smallTest.csv\"\n",
    "train_out = \"trainOut.labels\"\n",
    "test_out = \"testOut.labels\"\n",
    "metrics_out = \"metrics.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = [[int(code) for code in line.split(',')] for line in open(train_input,'r').read().splitlines()]\n",
    "test_file = [[int(code) for code in line.split(',')] for line in open(test_input,'r').read().splitlines()]\n",
    "\n",
    "train = np.array(train_file)\n",
    "test = np.array(test_file)\n",
    "train_y = np.copy(train[:,0])\n",
    "test_y = np.copy(test[:,0])\n",
    "\n",
    "train[:, 0] =  1  #initialize bias term, x0=1 is fixed\n",
    "test[:, 0] =  1  #initialize bias term \n",
    "\n",
    "\n",
    "if (init_flag==1): #random\n",
    "    alpha = np.random.random_sample((hidden_units,len(train[0]))/5 - 0.1)\n",
    "else:\n",
    "    alpha = np.zeros((hidden_units,len(train[0])))\n",
    "beta = np.zeros((10,hidden_units+1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_metrics = open(metrics_out,'w')\n",
    "train_out = open(train_out,'w')\n",
    "test_out = open(test_out,'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1 crossentropy(train): 2.185062761138787\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "\n",
      "epoch=1 crossentropy(test): 2.1882730258814203\n",
      "epoch=2 crossentropy(train): 1.9010325772656411\n",
      "6\n",
      "4\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "2\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "8\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "\n",
      "epoch=2 crossentropy(test): 1.9136380346124438\n",
      "error(train):0.77\n",
      "error(test):0.78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    #print(alpha)\n",
    "    entropy = {}\n",
    "    #print(epoch)\n",
    "    \n",
    "    for i in range(len(train)):\n",
    "        x = train[i]\n",
    "        y = train_y[i]    \n",
    "        probs,y_hat,z = NNforward(x,y,alpha,beta)\n",
    "        dLdAlpha, dLdBeta = NNBackward(x,y,alpha,beta,probs,z)\n",
    "        beta = beta - dLdBeta * learning_rate\n",
    "        alpha = alpha - dLdAlpha * learning_rate\n",
    "    \n",
    "    ent = 0\n",
    "    error_train = 0\n",
    "    #print(beta)\n",
    "    #print(alpha)\n",
    "    for i in range(len(train)):\n",
    "        x = train[i]\n",
    "        y = train_y[i]\n",
    "        probs,y_hat,z = NNforward(x,y,alpha,beta)\n",
    "        ent = entropy_loss(probs,y) + ent\n",
    "        if (epoch==num_epoch-1)\n",
    "            train_out.write(str(y_hat)+\"\\n\")\n",
    "        if (y_hat != y):\n",
    "            error_train = error_train +1\n",
    "    entropy[str(epoch)+\"train\"] = ent/len(train)\n",
    "    print(\"epoch=\"+str(epoch+1) + \" crossentropy(train): \" + str(ent/len(train)))\n",
    "    file_metrics.write(\"epoch=\"+str(epoch+1) + \" crossentropy(train): \" + str(ent/len(train))+\"\\n\")\n",
    "    \n",
    "    error_test= 0\n",
    "    ent_test = 0\n",
    "    for i in range(len(test)):\n",
    "        x = test[i]\n",
    "        y = test_y[i]\n",
    "        probs,y_hat,z = NNforward(x,y,alpha,beta)\n",
    "        ent_test = entropy_loss(probs,y) + ent_test\n",
    "        if (epoch==num_epoch-1):\n",
    "            test_out.write(str(y_hat)+\"\\n\")\n",
    "        #print(y_hat)\n",
    "        if (y_hat != y):\n",
    "            error_test = error_test +1\n",
    "    entropy[str(epoch)+\"test\"] = ent_test/len(test)\n",
    "    print(\"\\nepoch=\"+str(epoch+1) + \" crossentropy(test): \" + str(ent_test/len(test)))\n",
    "    file_metrics.write(\"epoch=\"+str(epoch+1) + \" crossentropy(test): \" + str(ent_test/len(test))+\"\\n\")\n",
    "print(\"error(train):\" +str(error_train/len(train)))\n",
    "print(\"error(test):\" +str(error_test/len(test)))\n",
    "file_metrics.write(\"error(train):\" +str(error_train/len(train))+\"\\n\")\n",
    "file_metrics.write(\"error(test):\" +str(error_test/len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_metrics.close()\n",
    "train_out.close()\n",
    "test_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
